{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9528660",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.data import Reader\n",
    "from cornac.eval_methods import RatioSplit\n",
    "\n",
    "# Load MovieLens 100K dataset\n",
    "reader = Reader()\n",
    "ml_data = reader.read(fpath='./datasets/ml-100k/u.data', fmt='UIRT', sep='\\t')\n",
    "\n",
    "# Define the evaluation metrics\n",
    "eval_method = RatioSplit(\n",
    "    data=ml_data,\n",
    "    test_size=0.2,\n",
    "    rating_threshold=0.0,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Rango de valores\n",
    "k_range = [10, 20, 30, 40, 50]\n",
    "lr_range = [0.001, 0.005, 0.01, 0.02]\n",
    "reg_range = [0.001, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Cantidad de combinaciones a generar\n",
    "num_trials = 10\n",
    "\n",
    "# Elegir 10 combinaciones aleatorias (con repetición)\n",
    "random_combinations = [\n",
    "    (\n",
    "        random.choice(k_range),\n",
    "        random.choice(lr_range),\n",
    "        random.choice(reg_range)\n",
    "    )\n",
    "    for _ in range(num_trials)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cornac.models import MF\n",
    "from cornac.metrics import RMSE, MAE, Precision, NDCG\n",
    "\n",
    "\n",
    "resultados_random = []\n",
    "\n",
    "for k, lr, reg in random_combinations:\n",
    "    print(f\"\\nEntrenando MF con k={k}, lr={lr}, reg={reg}\")\n",
    "\n",
    "    model = MF(\n",
    "        k=k,\n",
    "        learning_rate=lr,\n",
    "        lambda_reg=reg,\n",
    "        max_iter=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model.fit(eval_method.train_set)\n",
    "\n",
    "    metrics = eval_method.evaluate(\n",
    "        model,\n",
    "        metrics=[RMSE(), MAE(), Precision(k=5), NDCG(k=5)],\n",
    "        user_based=True\n",
    "    )\n",
    "\n",
    "    res = dict(metrics[0].metric_avg_results)\n",
    "    res.update({\"k\": k, \"lr\": lr, \"reg\": reg})\n",
    "    resultados_random.append(res)\n",
    "\n",
    "\n",
    "df_random = pd.DataFrame(resultados_random)\n",
    "df_random = df_random.sort_values(by=\"RMSE\")\n",
    "\n",
    "print(df_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73826a76",
   "metadata": {},
   "source": [
    "**Tabla de resultados de Random Search de hiperparámetros sobre MF**\n",
    "\n",
    "| Índice |  k  |   lr   |  reg   |   RMSE       |   MAE        | Precision@5      | NDCG@5      | Train (s)  | Test (s) |\n",
    "|--------|-----|--------|--------|--------------|--------------|------------------|-------------|------------|----------|\n",
    "|   0    |  40 | 0.005  | 0.001  | 0.987754     | 0.799558     | **0.088723**     | **0.09533** | 0.040255   | 0.651297 |\n",
    "|   1    |  30 | 0.001  | 0.001  | 0.910321     | 0.749434     | 0.068298         | 0.06378     | 0.036518   | 0.810599 |\n",
    "|   2    |  10 | 0.010  | 0.050  | 0.925274     | 0.754462     | 0.039149         | 0.03803     | 0.041386   | 0.692893 |\n",
    "|   3    |  40 | 0.020  | 0.001  | 1.175490     | 0.948993     | 0.050000         | 0.05052     | 0.055942   | 0.726719 |\n",
    "|   4    |  40 | 0.010  | 0.050  | 0.926032     | 0.755954     | 0.058936         | 0.06151     | 0.072233   | 1.167263 |\n",
    "|   5    |  10 | 0.010  | 0.010  | 0.995569     | 0.808141     | 0.039787         | 0.03835     | 0.022823   | 0.807756 |\n",
    "|   6    |  20 | 0.010  | 0.010  | 1.033805     | 0.836087     | 0.052766         | 0.05332     | 0.051659   | 0.679237 |\n",
    "|   7    |  10 | 0.020  | 0.100  | **0.905964** | **0.743172** | 0.014468         | 0.01270     | 0.023100   | -1.67645 |\n",
    "|   8    |  20 | 0.010  | 0.001  | 1.069231     | 0.859641     | 0.051277         | 0.05051     | 0.082295   | 0.781150 |\n",
    "|   9    |  40 | 0.020  | 0.010  | 1.086976     | 0.877900     | 0.055532         | 0.06012     | 0.050360   | 0.703733 |\n",
    "\n",
    "\n",
    "**Mejor precisión numérica (RMSE más bajo)**\n",
    "\n",
    "* Índice 7 (`k=10`, `lr=0.0020`, `reg=0.100`)\n",
    "* Mejor RMSE\n",
    "* Precision\\@5 y NDCG\\@5 muy bajo (1,4% y 1,3%)\n",
    "\n",
    "Este modelo predice mejor el rating real, pero recomienda mal. No es ideal para sistemas donde importa el Top-N.\n",
    "\n",
    "\n",
    "**Mejor ranking (Precision\\@5 y NDCG\\@5)**\n",
    "\n",
    "  * Índice 0 (`k=40`, `lr=0.005`, `reg=0.001`)\n",
    "  * Precision\\@5 = 0.0887\n",
    "  * NDCG\\@5 = 0.09533\n",
    "  * RMSE moerado: 0.9877 \n",
    "\n",
    "Este modelo ofrece las mejores recomendaciones ordenadas para el usuario.\n",
    "\n",
    "**Buen balance entre precisión y relevancia**\n",
    "\n",
    "* Índice 1 (`k=30`, `lr=0.001`, `reg=0.001`)\n",
    "* RMSE = 0.9103, MAE = 0.7494\n",
    "* Precision@5 = 0.0683, NDCG@5 = 0.0638\n",
    "\n",
    "Este modelo logra un buen equilibrio: errores bajos y recomendaciones razonablemente acertadas. Muy útil si buscás estabilidad general.\n",
    "\n",
    "**Modelos que conviene evitar**\n",
    "\n",
    "* Índices 3, 8 y 9: RMSE > 1.06, precisión y NDCG bajos.\n",
    "* Esto puede deberse a:\n",
    "  * Tasa de aprendizaje demasiado alta (lr=0.02)\n",
    "  * k muy alto con reg baja → sobreajuste o inestabilidad.\n",
    "\n",
    "Estos modelos probablemente no generalizan bien y ofrecen rankings pobres.\n",
    "\n",
    "\n",
    "**Variables evaluadas**\n",
    "\n",
    "| Hiperparámetro | Significado                                   |\n",
    "| -------------- | --------------------------------------------- |\n",
    "| `k`            | Dimensión de los vectores latentes (factores) |\n",
    "| `lr`           | Tasa de aprendizaje                           |\n",
    "| `reg`          | Término de regularización (L2)                |\n",
    "\n",
    "**Tendencias al aumentar `k` (número de factores latentes)**\n",
    "\n",
    "| Observación                                                    | Conclusión clave                                                      |\n",
    "| -------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| `k=10` o `k=20` tienden a ser más estables                     | Generan buen equilibrio entre precisión y relevancia                  |\n",
    "| `k=40` o `k=50` reduce RMSE pero puede dañar `Precision@5`     | Más capacidad para aprender, pero también mayor riesgo de sobreajuste |\n",
    "| `k=30` fue uno de los mejores balances                         | Buen rendimiento general con bajo error y buen ranking                |\n",
    "\n",
    "**Conclusión**: Aumentar `k` mejora precisión numérica (RMSE) hasta cierto punto, pero puede disminuir la calidad de las recomendaciones si no se regula bien.\n",
    "\n",
    "**Tendencias al variar `lr` (learning rate)**\n",
    "\n",
    "| Observación                                                                 | Conclusión clave                                        |\n",
    "| --------------------------------------------------------------------------- | ------------------------------------------------------- |\n",
    "| `lr=0.001` generó algunos de los mejores modelos de ranking (`Precision@5`) | Aprendizaje más lento pero más fino, evita oscilaciones |\n",
    "| `lr=0.005` balanceó RMSE y ranking en varios casos                          | Buena tasa media, rápida pero aún estable               |\n",
    "| `lr=0.02` empeoró RMSE y ranking en casi todos los casos                    | Tasa alta → aprendizaje inestable o salto de mínimos    |\n",
    "\n",
    "**Conclusión**: Tasas bajas (0.001–0.005) son más confiables. `lr=0.02` suele ser demasiado agresivo para MF.\n",
    "\n",
    "**Tendencias al modificar `reg` (regularización L2)**\n",
    "\n",
    "| Observación                                                 | Conclusión clave                                                           |\n",
    "| ----------------------------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| `reg=0.001` rindió bien en ranking, pero no siempre en RMSE | Baja penalización permite aprendizaje libre, pero riesgo de overfitting    |\n",
    "| `reg=0.1` bajó el RMSE pero redujo `Precision@5`            | Penaliza fuerte → buen ajuste general, pero limita flexibilidad del modelo |\n",
    "| `reg=0.01` fue el mejor punto medio en Grid Search          | Resultados equilibrados                                                    |\n",
    "\n",
    "**Conclusión**:\n",
    "\n",
    "* Mayor regularización → mejor RMSE\n",
    "* Menor regularización → mejor Precision\\@5\n",
    "\n",
    "---\n",
    "**Conclusión general**\n",
    "\n",
    "| Hiperparámetro | Aumentar...                             | Disminuir...                                           |\n",
    "| -------------- | --------------------------------------- | ------------------------------------------------------ |\n",
    "| `k`            | Mejora RMSE, reduce diversidad en Top-N | Reduce capacidad, pero mejora ranking si bien regulado |\n",
    "| `lr`           | Puede provocar errores grandes          | Mejora estabilidad y ranking                           |\n",
    "| `reg`          | Reduce overfitting, mejora RMSE         | Aumenta capacidad de ranking (con riesgo)              |\n",
    "\n",
    "\n",
    "**Para un buen balance entre RMSE y Precision\\@5**:\n",
    "\n",
    "* `k` ≈ 30\n",
    "* `lr` ≈ 0.001–0.005\n",
    "* `reg` ≈ 0.001–0.01\n",
    "\n",
    "Ideal al buscar tanto buenas predicciones como listas Top-N relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurarse de tener una copia limpia del DataFrame de random search\n",
    "df_random = pd.DataFrame(resultados_random)\n",
    "\n",
    "# Crear columna de configuración como string\n",
    "df_random['config'] = df_random.apply(\n",
    "    lambda row: f\"k={row['k']},lr={row['lr']},reg={row['reg']}\", axis=1\n",
    ")\n",
    "\n",
    "# Ordenar por RMSE para visualizar mejor\n",
    "df_random = df_random.sort_values(by='RMSE')\n",
    "\n",
    "# Crear gráfico\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# RMSE en eje izquierdo (rojo)\n",
    "ax1.plot(df_random['config'], df_random['RMSE'], 'o-', color='tab:red', label='RMSE')\n",
    "ax1.set_ylabel('RMSE', color='tab:red')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Precision@5 en eje derecho (azul)\n",
    "ax2.plot(df_random['config'], df_random['Precision@5'], 's--', color='tab:blue', label='Precision@5')\n",
    "ax2.set_ylabel('Precision@5', color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Títulos y ajustes visuales\n",
    "plt.title('Comparación de RMSE y Precision@5 - Random Search MF')\n",
    "ax1.set_xticks(range(len(df_random)))\n",
    "ax1.set_xticklabels(df_random['config'], rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
