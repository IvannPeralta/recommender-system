{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f52478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_threshold = 0.0\n",
      "exclude_unknowns = True\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1651\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1651\n",
      "Number of ratings = 19964\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6422ab718048729c36314e458341a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    }
   ],
   "source": [
    "from cornac.data import Reader\n",
    "from cornac.eval_methods import RatioSplit\n",
    "from cornac.models import MF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar dataset\n",
    "reader = Reader()\n",
    "data = reader.read(fpath='datasets/ml-100k/u.data', fmt='UIRT', sep='\\t')\n",
    "\n",
    "# Separaci√≥n entrenamiento/test\n",
    "eval_method = RatioSplit(\n",
    "    data=data,\n",
    "    test_size=0.2,\n",
    "    rating_threshold=0.0,\n",
    "    exclude_unknowns=True,\n",
    "    verbose=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Entrenar modelo\n",
    "model = MF(k=10, max_iter=50, learning_rate=0.01, verbose=True)\n",
    "model.fit(eval_method.train_set)\n",
    "\n",
    "# Historial de √≠tems vistos por usuario\n",
    "train_set = eval_method.train_set\n",
    "user_rated = {}\n",
    "\n",
    "user_indices, item_indices, _ = train_set.uir_tuple\n",
    "\n",
    "for uid, iid in zip(user_indices, item_indices):        # user_indices, item_indices son arrays paralelos ‚Üí zip itera sobre ambos a la vez.\n",
    "    if uid not in user_rated:\n",
    "        user_rated[uid] = set()\n",
    "    user_rated[uid].add(iid)\n",
    "\n",
    "# Todos los √≠tems posibles (√≠ndices internos)\n",
    "all_items_internal = set(train_set.iid_map.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde2b669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 generado para modelo MF\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 5\n",
    "\n",
    "def get_top_n(model, train_set, user_rated, all_items_internal, name=\"MF\"):\n",
    "    top_n = {}\n",
    "    for uid in train_set.uid_map.values():\n",
    "        seen = user_rated.get(uid, set())\n",
    "        candidates = all_items_internal - seen\n",
    "\n",
    "        scores = [(iid, model.score(uid, iid)) for iid in candidates]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = [iid for iid, _ in scores[:TOP_N]]\n",
    "        \n",
    "    print(f\"Top-{TOP_N} generado para modelo {name}\")\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(model, train_set, user_rated, all_items_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "829d8a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√çtems m√°s populares (top 5):\n",
      "√çtem 92 ‚Üí Popularidad: 1.0000\n",
      "√çtem 305 ‚Üí Popularidad: 0.8981\n",
      "√çtem 212 ‚Üí Popularidad: 0.8684\n",
      "√çtem 76 ‚Üí Popularidad: 0.8599\n",
      "√çtem 188 ‚Üí Popularidad: 0.8365\n"
     ]
    }
   ],
   "source": [
    "# La popularidad de un √≠tem se puede medir como la cantidad de veces que aparece en el set de entrenamiento. Es decir, cu√°ntos usuarios lo han calificado.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Contar cu√°ntas veces aparece cada √≠tem en el entrenamiento\n",
    "item_counts = Counter(item_indices)\n",
    "\n",
    "# Normalizar popularidad a valores entre 0 y 1\n",
    "max_count = max(item_counts.values())\n",
    "item_popularity = {iid: count / max_count for iid, count in item_counts.items()}\n",
    "\n",
    "# Mostrar ejemplo\n",
    "sorted_pop = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"√çtems m√°s populares (top 5):\")\n",
    "for iid, pop in sorted_pop[:5]:\n",
    "    print(f\"√çtem {iid} ‚Üí Popularidad: {pop:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8988d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Popularidad promedio de las recomendaciones: 0.2877\n"
     ]
    }
   ],
   "source": [
    "def promedio_popularidad(top_n, item_popularity):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for recs in top_n.values():\n",
    "        for iid in recs:\n",
    "            total += item_popularity.get(iid, 0)\n",
    "            count += 1\n",
    "    return total / count if count > 0 else 0\n",
    "\n",
    "pop_promedio = promedio_popularidad(top_n, item_popularity)\n",
    "print(f\" Popularidad promedio de las recomendaciones: {pop_promedio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f74a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 con penalizaci√≥n generada (Œª=0.5)\n",
      "Popularidad promedio (reranked): 0.1683\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_reranked(model, train_set, user_rated, all_items, item_popularity, top_n=5, lambda_=0.5):\n",
    "    reranked_top_n = {}\n",
    "\n",
    "    for uid in train_set.uid_map.values():\n",
    "        seen = user_rated.get(uid, set())\n",
    "        candidates = all_items - seen\n",
    "\n",
    "        penalized_scores = []\n",
    "        for iid in candidates:\n",
    "            score = model.score(uid, iid)\n",
    "            popularity = item_popularity.get(iid, 0)\n",
    "            penalized_score = score - lambda_ * popularity\n",
    "            penalized_scores.append((iid, penalized_score))\n",
    "\n",
    "        penalized_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        reranked_top_n[uid] = [iid for iid, _ in penalized_scores[:top_n]]\n",
    "\n",
    "    print(f\"Top-{top_n} con penalizaci√≥n generada (Œª={lambda_})\")\n",
    "    return reranked_top_n\n",
    "\n",
    "\n",
    "lambda_penalizacion = 0.5\n",
    "top_n_rerank = get_top_n_reranked(\n",
    "    model, train_set, user_rated, all_items_internal,\n",
    "    item_popularity, top_n=5, lambda_=lambda_penalizacion\n",
    ")\n",
    "\n",
    "pop_rerank = promedio_popularidad(top_n_rerank, item_popularity)\n",
    "print(f\"Popularidad promedio (reranked): {pop_rerank:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e6bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Popularidad promedio original: 0.2877\n",
      "Popularidad promedio reranjed: 0.1683\n",
      "Precision@5 original: 0.0836\n",
      "Precision@5 rerankeado: 0.0472\n"
     ]
    }
   ],
   "source": [
    "# Calcular Precision@5 para ambos conjuntos de recomendaciones\n",
    "from cornac.metrics import Precision\n",
    "\n",
    "# Crear mapa item_id -> item_index interno\n",
    "item_id2index = {v: k for k, v in train_set.iid_map.items()}\n",
    "\n",
    "# Crear ground truth del test set\n",
    "test_set = eval_method.test_set\n",
    "ground_truth = {}\n",
    "\n",
    "for uid, iid, _ in zip(*test_set.uir_tuple):\n",
    "    ground_truth.setdefault(uid, set()).add(iid)\n",
    "\n",
    "# Precision@5\n",
    "def precision_at_k(top_n, ground_truth, k=5):\n",
    "    precisiones = []\n",
    "    for uid, recs in top_n.items():\n",
    "        gt = ground_truth.get(uid, set())\n",
    "        if not gt:\n",
    "            continue\n",
    "        hits = sum([1 for iid in recs if iid in gt])\n",
    "        precisiones.append(hits / k)\n",
    "    return np.mean(precisiones)\n",
    "\n",
    "precision_original = precision_at_k(top_n, ground_truth)\n",
    "precision_rerank = precision_at_k(top_n_rerank, ground_truth)\n",
    "\n",
    "print(f\"Popularidad promedio original: {pop_promedio:.4f}\")\n",
    "print(f\"Popularidad promedio reranjed: {pop_rerank:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"Precision@5 original: {precision_original:.4f}\")\n",
    "print(f\"Precision@5 rerankeado: {precision_rerank:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ce888",
   "metadata": {},
   "source": [
    "**Tabla comparativa de resultados**\n",
    "\n",
    "| M√©trica              | Recomendaci√≥n Original | Recomendaci√≥n Rerankeada |\n",
    "| ---------------------| ---------------------- | ------------------------ |\n",
    "| Precision\\@5         | 0.0836                 | 0.0472                   |\n",
    "| Popularidad Promedio | 0.2877                 | 0.1683                   |\n",
    "\n",
    "**El modelo original prioriza √≠tems populares**\n",
    "\n",
    "* La popularidad promedio de 0.2877 indica que el modelo MF tiende a recomendar los √≠tems m√°s frecuentemente vistos.\n",
    "* Este comportamiento es com√∫n en modelos entrenados solo con historial de interacci√≥n, sin ninguna correcci√≥n.\n",
    "\n",
    "**El re-ranking penaliza la popularidad efectivamente**\n",
    "\n",
    "* Con `Œª = 0.5`, la popularidad promedio baj√≥ a 0.1683.\n",
    "* Esto significa que el sistema ahora recomienda √≠tems m√°s variados y menos populares, mejorando la equidad en la exposici√≥n.\n",
    "\n",
    "**La precisi√≥n disminuy√≥**\n",
    "\n",
    "* La `Precision@5` baj√≥ de 0.0836 a 0.0472.\n",
    "* Esto refleja un trade-off inevitable: al diversificar, se pierde algo de precisi√≥n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
